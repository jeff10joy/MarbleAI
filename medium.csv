,0
Tag,computer vision
Author,Joy Jefferson
Timestamp,"Jun 30, 2020·5 min read"
Content,"['YOLO(You Look Only Once) Algorithm V2:\nAs a key use of image processing, object detection has boomed along with the unprecedented advancement of Convolutional Neural Network (CNN) . Thus, the most urgent requirement of object detection improvement is to accelerate the speed. This article exhibits CNN representatives You Only Look Once (YOLO), which innovates a complete new way of solving the object detection with most simple and high efficient way.\nHumans glance at an image and instantly know what objects are in the image, where they are, and how they interact. If algorithms for image processing could be accurate and fast enough, the computers would be able to drive cars without specialized sensors, and assistive devices would be able to convey real-time scene information to users. Likewise, if these algorithms could complete Deep Learning (DL) tasks with high efficient and excellent performance like human beings do, it would be real Artificial Intelligent (AI). Thus, the core tasks of image processing are a serial of recognition: classification, localization and object detection and the key challenges are: accuracy, speed, cost.\nTypical YOLO architecture:\nFew Fundamental concepts of CNN:\n1). Convolutional Layer:\nThe essential point of the convolutional layer is to find out about the component of the pictures(such as edges). The convolutional layer comprises of a few element maps, which comprises number of neurons. Every neuron of an element map is utilized to extricate nearby qualities of various positions in the previous layer.\n2. Pooling Layer:\nSimilar to the Convolutional Layer, the Pooling layer is responsible for reducing the spatial size of the Convolved Feature. This is to decrease the computational power required to process the data through dimensionality reduction. Furthermore, it is useful for extracting dominant features which are rotational and positional invariant, thus maintaining the process of effectively training of the model.\n3.Fully Connected Layer:\nThe completely connected or associated layer in the Convolutional Neural Network takes every one of the neurons from the past layer and interfaces them to each and every neuron of the present layer. No spatial data is saved in these completely associated layers. The last completely associated layer is constantly trailed by a yield layer.\nBounding boxes: The box that encases the detected image or object\nClass probabilities: The probability of a detected image belongs to a specific class.\nWorking:\n1. YOLO first takes an input image .\n2.The framework then divides the input image into S x S grids:\n3. Image classification and localization are applied on each grid.\nYOLO then predicts B bounding boxes and their corresponding class probabilities for objects.\nIt detects only one object regardless of number of bounding boxes.\nIf the center of an object falls into a grid cell, that grid cell is responsible for detecting that object. Each grid cell predicts B bounding boxes, confidence scores for those boxes and C class probabilities of the grid. Only if these predictions are above the given threshold the object is detected\nclass confidence score = box confidence score x conditional class probability\nIt measures confidence on both the classification and localization(i.e. where an object is located)\nIOU stands for intersection over union\nSuppose the predicted bounding box encases only over a region of the image ,an union and an intersection is taken between the predicted bounding box and the actual bounding box(ground truth).\nIOU=size of intersection/size of union.\nThe Loss Function:\nSince multiple bounding boxes are predicted for the same object per grid,we want only one of them to be responsible for the object,hence the loss computed to find true positive. Generally ones with high IOU with the ground truth is selected.\nYOLO uses sum squared error between the predictions and the ground truth to calculate loss.\nThe loss functions are:\n1). The classification loss(it is the error between conditional class probabilities and the ground truth)\n2).The localization loss(it is the error between the predicted boundary box and the ground truth.\n3).The confidence loss( if an object is detected in the box).\nThe sum of these respective losses gives the total loss function.\nExplanation of these terms:\nXi,Yi is the location of centroid of the bounding boxes.\nWi,hi is the width and height of the bounding boxes.\nCi is the confidence score of whether an object is there in the bounding box or not.\npi(c) is the probability if the predicted image belongs to a specific class.\nWhile training the network if it predicts an object when the object is actually not there, we’ll need to penalize it ,which is done by masking\nIf initially there was an object the first term is equated 1 and when there is no object it is equated to 0. The second term is just inverse of the first one, when no object it is equated to 1 and 0 otherwise.\nThe three lambdas are just constants to take in account more than one aspect of the loss functions. In this formula lambda coord has been given the highest value, to give first term more importance.\nNon- Max suppression function:\nSince YOLO predicts more than one bounding box for the same object,hence non max suppression is applied to remove boxes with low class confidence scores.\n1). Firstly, the predictions are sorted by the confidence scores.\n2). Discard all boxes with scores<=0.6\n3). Select the box with with highest Pr(class) and discard others.\n4).Discard any remaining boxes with IOU>=0.5 with the s\nAdvantages of YOLO:\n1). Fast, accurate and applied highly in real time processing such as autonomous driving.\n2).YOLO is more generalized.\n3).YOLO detects one object per grid cell.It enforces spatial diversity in making predictions.\nReferences:\nhttps://stats.stackexchange.com/questions/287486/yolo-loss-function-explanation\nA Comprehensive Guide to Convolutional Neural Networks — the ELI5 way\nArtificial Intelligence has been witnessing a monumental growth in bridging the gap between the capabilities of humans…\ntowardsdatascience.com\nhttps://cs231n.github.io/convolutional-networks/\nhttps://iopscience.iop.org/article/10.1088/1742-6596/1004/1/012029/meta']"
